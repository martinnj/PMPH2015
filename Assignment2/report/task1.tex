\section{Task I: CUDA}

\subsection{a) Exclusive Scan}
\todo[inline]{Finish implementation and report results.}

\subsection{b) Maximum Segment Sum}

The solution to the task can be found in the \textit{src/mss} folder and
contains a makefile that supports the \texttt{compile}, \texttt{run},
\texttt{clean} options.

As ofr the run time, when the list of integers reach a length of approximately
10.000 elements the CPU and GPU takes almost the same time to complete the
calculation (CPU: 650 microseconds, GPU: 750 microseconds). When using the
\texttt{make run} command, the program will run a number of tests of the mss
code with varying input lengths and report the time taken. The times include the
time taken to copy the input from the host to the device.

\subsection{c) Sparse Matrix Multiplication}

The current solution to this task can be found in the
\textit{src/matrixmul} folder. The haskell code can be run by using
\texttt{\$ runhaskell PrimesQuicksort.hs}. The code for producing the results
can be seen in the aformentioned file or in Figure \ref{fig:t1c1code} and Figure
\ref{fig:t1c2code}.

\begin{figure}[H]
    \begin{lstlisting}
nestSparseMatVctMult :: [[(Int,Double)]] -> [Double] -> [Double]
nestSparseMatVctMult mat x =
    map (\row ->  sum $ (map (\(i,n) -> n*(x!!i)) row) ) mat
    \end{lstlisting}
    \caption{Nested implementation of sparse matrix and vector multiplication.}
    \label{fig:t1c1code}
\end{figure}

\begin{figure}[H]
    \begin{lstlisting}
        flatSparseMatVctMult :: [Int] -> [(Int,Double)] -> [Double] -> [Double]
        flatSparseMatVctMult flags mat x =
            let comps = map (\(a,b) -> b*(x!!a)) mat
                sums = segmScanInc (+) 0 flags comps
                end_flags = tail flags ++ [head flags]
                foo = zip end_flags sums
                (vals, ff) = parFilter (\(a,b) -> a == 1) foo
                (_, res) = unzip $ take (head ff) vals
            in res
    \end{lstlisting}
    \caption{The flat implementation of sparse matrix and vector
    multiplication.}
    \label{fig:t1c2code}
\end{figure}

The second part of the assignment is to implement this in C++ using CUDA, the files
for the solution of this task is also found in: \textit{src/matrixmul}, and can
be compiled using the supplied make file, which supports the \texttt{clean},
\texttt{compile} and \texttt{run} targets. When the program is run, it will run
on the same example data as the haskell version, and print the resulting vector.

The C++ code is more or less a line for line conversion of the haskell code,
except for the three lines after \texttt{end\_flags} is declared which was
rewritten to a single kernel.
