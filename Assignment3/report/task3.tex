\section{Task 3: Dense Matrix Multiplication}
The code for this assignment can be found in the \textit{src/Task3} folder
handed in with this report. All functions (where applicable) have been templated
so the datatype contianed in the matrices can be any class \texttt{T}.

The code ships with a make file that supports the \texttt{clean},
\texttt{compile} and \texttt{run} targets. The current setup of the file will
run both GPU kernels on an assymetric matrix and compare to the CPU runs.

\subsection{Task 3.a: Sequential CPU Code}
The code for this task is mainly found in the \textit{cpuFunc.cu.h} file, like
earlier it contains a number of convinience functions as well as the
multiplication function \texttt{flatMatrixMultiply}.

\subsection{Task 3.c: Naive GPU Code}
The code for this task is found in the \textit{gpuFunc.cu.h} file, it contains
the same convinience functions as earlier, but the kernel is now replaced with
\texttt{flatNaiveMutliplyKernel}, which is a naive matrix multiplication kernel.

\subsection{Task 3.d: Shared-Memory GPU Code}
The code for this task is found in the \textit{gpuFunc.cu.h} file, the
shared-memory kernel is implemented in the function
\texttt{flatSharedMultiplyKernel}.

\subsection{Runningtimes}

Table \ref{tab:task3time} shows the running times of the CPU code and the
Shared-Memory GPU kernel. Time time is done for 1000 runs of each method and the
time represents the average time for a single run. The times only cover the time
spent in the calulation kernels, and does not cover the overhead for copying
data to device memory.

\begin{table}
    \begin{tabular}{|r|r|r|r|}
        \hline
        \textbf{Matrix Dimensions} & \textbf{CPU Time} & \textbf{Naive GPU Time} & \textbf{Shared-Memory GPU Time}\\\hline
        $10 \times  10$ & $  10\mu s$ & $8\mu s$ & $7\mu s$ \\
        $20 \times  20$ & $  85\mu s$ & $8\mu s$ & $7\mu s$ \\
        $30 \times  30$ & $ 272\mu s$ & $8\mu s$ & $7\mu s$ \\
        $40 \times  40$ & $ 635\mu s$ & $8\mu s$ & $7\mu s$ \\
        $50 \times  50$ & $1228\mu s$ & $8\mu s$ & $7\mu s$ \\
        $60 \times  60$ & $2107\mu s$ & $8\mu s$ & $7\mu s$ \\\hline

    \end{tabular}
    \caption{The running times for the CPU and GPU code as the average over 1000
    runs.}
    \label{tab:task3time}
\end{table}

Table \ref{tab:task3time} shows that the CPU based code starts out slower than
both the GPU kernels, it also shows that the shared-memory kernel have a lower
runtime than the naive kernel.
